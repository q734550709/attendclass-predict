experiment:
  name: "stacking_model"
  description: "多层模型实验配置"

# 实验日志配置
logging:
  level: INFO
  save_path: "../../experiments/target2/model_stack/tune001/logs"

# 模型配置
model:
  # 是否使用多层模型
  is_stacking: true
  params:
    random_state: 42          # 随机种子
  
  # 特征选择器配置（可选）
  feature_selector:
    enabled: true
    type: "lightgbm"
    params:
      learning_rate: 0.1
      n_estimators: 100
      random_state: 42
      objective: "binary"
    threshold: 0.05  # 特征选择阈值
  
  # 基础模型配置（用于多层模型）
  base_models:
    - name: "xgb"
      type: "xgboost"
      params:
        max_depth: 3
        learning_rate: 0.1
        n_estimators: 100
        random_state: 42
        objective: "binary:logistic"
        eval_metric: "logloss"
        
    - name: "rf"
      type: "random_forest"
      params:
        n_estimators: 100
        criterion: "gini" 
        max_depth:
        random_state: 42
        
    - name: "gbdt"
      type: "gbdt"
      params:
        loss: "log_loss"          # 损失函数
        learning_rate: 0.1        # 学习率
        n_estimators: 100         # 树的数量
        max_depth: 3              # 树的最大深度
        random_state: 42          # 随机种子
  
  # 元学习器配置（用于多层模型）
  meta_learner:
    type: "logistic_reg"
    params:
      penalty: "l2"
      C: 1.0
      max_iter: 100
      random_state: 42
  
  # 单模型配置（当is_stacking为false时使用）
  single_model:
    type: "lightgbm"
    params:
      max_depth: -1
      learning_rate: 0.1
      n_estimators: 100
      random_state: 42
      objective: "binary"

# 数据配置
data:
  paths:
    X_train: "../../data/processed/next_four/X_train.csv"
    y_train: "../../data/processed/next_four/y_train.csv"
    X_test: "../../data/processed/next_four/X_test.csv"
    y_test: "../../data/processed/next_four/y_test.csv"

# 交叉验证配置
cross_validation:
  n_splits: 5

# 输出配置
output:
  exp_dir: "../../experiments/target2/model_stack/tune001/metrics"
  exp_model_dir: "../../models/trained/target2/model_stack/tune001" 

# 随机搜索参数配置
random_search_params:
  # 特征选择器参数分布
  feature_selector_param_distributions:
    learning_rate: [0.01, 0.05, 0.1, 0.3]
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 4, 5, 6, 7]
    num_leaves: [7, 15, 31, 63]
    min_child_samples: [10, 20, 30, 50]
    subsample: [0.6, 0.7, 0.8, 0.9]
    colsample_bytree: [0.6, 0.7, 0.8, 0.9]
    reg_alpha: [0, 0.1, 0.5, 1.0]
    reg_lambda: [0, 0.1, 0.5, 1.0]
  
  # 特征选择阈值分布
  feature_selector_threshold: [0.01, 0.05, 0.1, 0.15, 0.2]

  # 基础模型参数分布
  base_models_param_distributions:
    xgb:
      max_depth: [3, 4, 5, 6, 7, 8, 9]
      learning_rate: [0.01, 0.05, 0.1, 0.3]
      n_estimators: [100, 200, 300, 400]
      min_child_weight: [1, 3, 5, 7]
      subsample: [0.6, 0.7, 0.8, 0.9]
      colsample_bytree: [0.6, 0.7, 0.8, 0.9]
      gamma: [0, 0.1, 0.2, 0.3]
    
    rf:
      n_estimators: [100, 200, 300, 400]
      max_depth: [3, 4, 5, 6, 7, 8, 9]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      max_features: ["sqrt", "log2"]
    
    gbdt:
      max_depth: [3, 4, 5, 6, 7]
      learning_rate: [0.01, 0.05, 0.1, 0.3]
      n_estimators: [100, 200, 300, 400]
      subsample: [0.6, 0.7, 0.8, 0.9]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
  
  # 元学习器参数分布
  meta_learner_param_distributions:
    C: [0.001, 0.01, 0.1, 1.0, 10.0]
    max_iter: [100, 200, 300]
    penalty: ["l1", "l2"]
    solver: ["liblinear", "saga"]
  
  n_iter: 100
  scoring: "recall"
  cv: 5
  n_jobs: -1
  random_state: 42
  return_train_score: true

# 网格搜索参数配置
grid_search_params:
  # 特征选择器参数网格
  feature_selector_param_grid:
    learning_rate: [0.01, 0.1]
    n_estimators: [100, 200]
    max_depth: [3, 5]
    num_leaves: [15, 31]
    min_child_samples: [20, 30]
    subsample: [0.8, 0.9]
    colsample_bytree: [0.8, 0.9]
    reg_alpha: [0, 0.5]
    reg_lambda: [0, 0.5]
  
  # 特征选择阈值网格
  feature_selector_threshold: [0.05, 0.1, 0.15]

  # 基础模型参数网格
  base_models_param_grid:
    xgb:
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1]
      n_estimators: [100, 200]
      min_child_weight: [1, 5]
      subsample: [0.8, 0.9]
      colsample_bytree: [0.8, 0.9]
      gamma: [0, 0.1]
    
    rf:
      n_estimators: [100, 200]
      max_depth: [3, 5, 7]
      min_samples_split: [2, 5]
      min_samples_leaf: [1, 2]
      max_features: ["sqrt", "log2"]
    
    gbdt:
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1]
      n_estimators: [100, 200]
      subsample: [0.8, 0.9]
      min_samples_split: [2, 5]
      min_samples_leaf: [1, 2]
  
  # 元学习器参数网格
  meta_learner_param_grid:
    C: [0.01, 0.1, 1.0]
    max_iter: [100, 200]
    penalty: ["l1", "l2"]
    solver: ["liblinear", "saga"]
  
  scoring: "recall"
  cv: 5
  n_jobs: -1
  return_train_score: true

# HalvingRandomSearchCV参数配置
halving_random_search_params:
  # 特征选择器参数分布
  feature_selector_param_distributions:
    learning_rate: [0.01, 0.05, 0.1, 0.3]
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 4, 5, 6, 7]
    num_leaves: [7, 15, 31, 63]
    min_child_samples: [10, 20, 30, 50]
    subsample: [0.6, 0.7, 0.8, 0.9]
    colsample_bytree: [0.6, 0.7, 0.8, 0.9]
    reg_alpha: [0, 0.1, 0.5, 1.0]
    reg_lambda: [0, 0.1, 0.5, 1.0]
  
  # 特征选择阈值分布
  feature_selector_threshold: [0.01, 0.05, 0.1, 0.15, 0.2]

  # 基础模型参数分布
  base_models_param_distributions:
    xgb:
      max_depth: [3, 4, 5, 6, 7, 8, 9]
      learning_rate: [0.01, 0.05, 0.1, 0.3]
      n_estimators: [100, 200, 300, 400]
      min_child_weight: [1, 3, 5, 7]
      subsample: [0.6, 0.7, 0.8, 0.9]
      colsample_bytree: [0.6, 0.7, 0.8, 0.9]
      gamma: [0, 0.1, 0.2, 0.3]
    
    rf:
      n_estimators: [100, 200, 300, 400]
      max_depth: [3, 4, 5, 6, 7, 8, 9]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      max_features: ["sqrt", "log2"]
    
    gbdt:
      max_depth: [3, 4, 5, 6, 7]
      learning_rate: [0.01, 0.05, 0.1, 0.3]
      n_estimators: [100, 200, 300, 400]
      subsample: [0.6, 0.7, 0.8, 0.9]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
  
  # 元学习器参数分布
  meta_learner_param_distributions:
    C: [0.001, 0.01, 0.1, 1.0, 10.0]
    max_iter: [100, 200, 300]
    penalty: ["l1", "l2"]
    solver: ["liblinear", "saga"]
  
  n_candidates: 'exhaust'
  factor: 2
  resource: 'n_samples'
  scoring: "recall"
  cv: 5
  refit: true
  n_jobs: -1
  random_state: 42
  return_train_score: true

# HalvingGridSearchCV参数配置
halving_grid_search_params:
  # 特征选择器参数网格
  feature_selector_param_grid:
    learning_rate: [0.01, 0.1]
    n_estimators: [100, 200]
    max_depth: [3, 5]
    num_leaves: [15, 31]
    min_child_samples: [20, 30]
    subsample: [0.8, 0.9]
    colsample_bytree: [0.8, 0.9]
    reg_alpha: [0, 0.5]
    reg_lambda: [0, 0.5]
  
  # 特征选择阈值网格
  feature_selector_threshold: [0.05, 0.1, 0.15]

  # 基础模型参数网格
  base_models_param_grid:
    xgb:
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1]
      n_estimators: [100, 200]
      min_child_weight: [1, 5]
      subsample: [0.8, 0.9]
      colsample_bytree: [0.8, 0.9]
      gamma: [0, 0.1]
    
    rf:
      n_estimators: [100, 200]
      max_depth: [3, 5, 7]
      min_samples_split: [2, 5]
      min_samples_leaf: [1, 2]
      max_features: ["sqrt", "log2"]
    
    gbdt:
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1]
      n_estimators: [100, 200]
      subsample: [0.8, 0.9]
      min_samples_split: [2, 5]
      min_samples_leaf: [1, 2]
  
  # 元学习器参数网格
  meta_learner_param_grid:
    C: [0.01, 0.1, 1.0]
    max_iter: [100, 200]
    penalty: ["l1", "l2"]
    solver: ["liblinear", "saga"]
  
  factor: 2
  resource: 'n_samples'
  scoring: "recall"
  cv: 5
  refit: true
  n_jobs: -1
  random_state: 42
  return_train_score: true 

# 贝叶斯优化参数配置
bayesian_search_params:
  # 特征选择器参数空间
  feature_selector_param_space:
    learning_rate:
      type: "real"
      low: 0.01
      high: 0.3
      prior: "log-uniform"
    n_estimators:
      type: "int"
      low: 100
      high: 300
      prior: "log-uniform"
    max_depth:
      type: "int"
      low: 3
      high: 7
    num_leaves:
      type: "int"
      low: 15
      high: 127
    min_child_samples:
      type: "int"
      low: 10
      high: 50
  
  # 特征选择阈值空间
  feature_selector_threshold:
    type: "real"
    low: 0.01
    high: 0.3

  # 基础模型参数空间
  base_models_param_space:
    xgb:
      max_depth:
        type: "int"
        low: 3
        high: 9
      learning_rate:
        type: "real"
        low: 0.05
        high: 0.3
        prior: "log-uniform"
      n_estimators:
        type: "int"
        low: 100
        high: 400
      gamma:
        type: "real"
        low: 0.0
        high: 0.3

    rf:
      n_estimators:
        type: "int"
        low: 100
        high: 400
      max_depth:
        type: "int"
        low: 3
        high: 9
      min_samples_split:
        type: "int"
        low: 2
        high: 100
      max_features:
        type: "categorical"
        choices: ["sqrt", "log2"]
    
    gbdt:
      max_depth:
        type: "int"
        low: 3
        high: 7
      learning_rate:
        type: "real"
        low: 0.05
        high: 0.3
        prior: "log-uniform"
      n_estimators:
        type: "int"
        low: 100
        high: 300
      subsample:
        type: "real"
        low: 0.6
        high: 0.9
      max_features:
        type: "categorical"
        choices: ["sqrt", "log2"]
  
  # 元学习器参数空间
  meta_learner_param_space:
    C:
      type: "real"
      low: 0.001
      high: 10.0
      prior: "log-uniform"
    max_iter:
      type: "int"
      low: 100
      high: 300
    penalty:
      type: "categorical"
      choices: ["l1", "l2"]
    solver:
      type: "categorical"
      choices: ["liblinear", "saga"]
  
  # 贝叶斯优化的其他参数
  n_trials: 2                # 优化迭代次数
  n_startup_trials: 10         # 随机初始化的试验次数
  scoring: "recall"            # 优化目标指标
  cv: 5                        # 交叉验证折数
  n_jobs: -1                   # 并行作业数
  random_state: 42            # 随机种子
  return_train_score: true    # 是否返回训练集分数
  acquisition_function: "EI"   # 采集函数类型 (EI: Expected Improvement)
  n_points: 1                 # 每次迭代评估的点数